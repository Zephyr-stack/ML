{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data/sign-lang')\n",
    "if os.path.isdir('train/0/') is False:\n",
    "    os.makedirs('train')\n",
    "    os.makedirs('valid')\n",
    "    os.makedirs('test')\n",
    "    for i in range(0,10):\n",
    "        shutil.move(f'{i}','train')\n",
    "        os.makedirs(f'valid/{i}')\n",
    "        os.makedirs(f'test/{i}')\n",
    "        valid_samples=random.sample(os.listdir(f'train/{i}'),30)\n",
    "        for c in valid_samples:\n",
    "            shutil.move(f'train/{i}/{c}',f'valid/{i}')\n",
    "        test_samples=random.sample(os.listdir(f'train/{i}'),5)\n",
    "        for c in test_samples:\n",
    "            shutil.move(f'train/{i}/{c}',f'test/{i}')\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='/Users/sarthak/Desktop/Important/Machine learning/data/sign-lang/train'\n",
    "valid_path='/Users/sarthak/Desktop/Important/Machine learning/data/sign-lang/valid'\n",
    "test_path='/Users/sarthak/Desktop/Important/Machine learning/data/sign-lang/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1712 images belonging to 10 classes.\n",
      "Found 300 images belonging to 10 classes.\n",
      "Found 50 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=train_path,target_size=(224,224),batch_size=10)\n",
    "valid_batch=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=valid_path,target_size=(224,224),batch_size=10)\n",
    "test_batch=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=test_path,target_size=(224,224),batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile=tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mobile.layers[-6].output\n",
    "output=Dense(units=10,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=mobile.inputs,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps, validate for 30 steps\n",
      "Epoch 1/30\n",
      "172/172 - 82s - loss: 0.7784 - accuracy: 0.7605 - val_loss: 1.1791 - val_accuracy: 0.5833\n",
      "Epoch 2/30\n",
      "172/172 - 76s - loss: 0.1066 - accuracy: 0.9895 - val_loss: 0.9274 - val_accuracy: 0.6967\n",
      "Epoch 3/30\n",
      "172/172 - 75s - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.7467\n",
      "Epoch 4/30\n",
      "172/172 - 76s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.7600\n",
      "Epoch 5/30\n",
      "172/172 - 77s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.7700\n",
      "Epoch 6/30\n",
      "172/172 - 77s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.8067\n",
      "Epoch 7/30\n",
      "172/172 - 75s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8200\n",
      "Epoch 8/30\n",
      "172/172 - 75s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5846 - val_accuracy: 0.8067\n",
      "Epoch 9/30\n",
      "172/172 - 75s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.8167\n",
      "Epoch 10/30\n",
      "172/172 - 76s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8400\n",
      "Epoch 11/30\n",
      "172/172 - 75s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.8433\n",
      "Epoch 12/30\n",
      "172/172 - 75s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8467\n",
      "Epoch 13/30\n",
      "172/172 - 76s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8433\n",
      "Epoch 14/30\n",
      "172/172 - 77s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.8500\n",
      "Epoch 15/30\n",
      "172/172 - 78s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8533\n",
      "Epoch 16/30\n",
      "172/172 - 77s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.8600\n",
      "Epoch 17/30\n",
      "172/172 - 94s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.8600\n",
      "Epoch 18/30\n",
      "172/172 - 101s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.8567\n",
      "Epoch 19/30\n",
      "172/172 - 98s - loss: 9.3996e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8567\n",
      "Epoch 20/30\n",
      "172/172 - 101s - loss: 8.2914e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8600\n",
      "Epoch 21/30\n",
      "172/172 - 98s - loss: 7.3294e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8633\n",
      "Epoch 22/30\n",
      "172/172 - 97s - loss: 6.4971e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8700\n",
      "Epoch 23/30\n",
      "172/172 - 100s - loss: 5.7811e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8667\n",
      "Epoch 24/30\n",
      "172/172 - 96s - loss: 5.1575e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "172/172 - 96s - loss: 4.6167e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "172/172 - 97s - loss: 4.1259e-04 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8700\n",
      "Epoch 27/30\n",
      "172/172 - 98s - loss: 3.7019e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8700\n",
      "Epoch 28/30\n",
      "172/172 - 97s - loss: 3.3204e-04 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.8700\n",
      "Epoch 29/30\n",
      "172/172 - 96s - loss: 2.9871e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8800\n",
      "Epoch 30/30\n",
      "172/172 - 99s - loss: 2.6903e-04 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec2dead3d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batch,validation_data=valid_batch,epochs=30,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 2s\n"
     ]
    }
   ],
   "source": [
    "p=model.predict(x=test_batch,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_true=test_batch.classes,y_pred=np.argmax(p,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0\n"
     ]
    }
   ],
   "source": [
    "print(cm.trace()/cm.sum()*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
